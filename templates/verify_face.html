<!DOCTYPE html>
{% load static %}
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="{% static 'assets/js/face/face-api.min.js' %}"></script>
    <title>Face Recognition</title>
    <style>
        body {
            text-align: center;
            font-family: Arial, sans-serif;
        }
        #logo {
            margin-top: 20px;
        }
        #videoContainer {
            position: relative;
            display: inline-block;
        }
        #videoElement {
            width: 80%;
            height: auto;
            margin-top: 20px;
        }
        #canvas {
            position: absolute;
            top: 0;
            left: 0;
        }
        #startButton {
            margin-top: 20px;
            padding: 10px 20px;
            font-size: 16px;
            cursor: pointer;
        }

        body {
      margin: 0;
      padding: 0;
      width: 100vw;
      height: 100vh;
      display: flex;
      justify-content: center;
      align-items: center;
    }

    canvas {
      position: absolute;
      left: 0;
      top:0;
    }
    </style>
</head>
<body>

    <!-- Logo at the top -->
    <!-- <img src="https://res.cloudinary.com/dlqaoh20g/image/upload/v1738567754/e953viq5rtyueic9ea0c.png" id="logo" alt="Logo" width="200"> -->
    
    <!-- Video element with canvas overlay for face detection -->
    <!-- <h2>Live Face Recognition</h2> -->
    
    <div style="position: relative" id="container">
        <video id="video" style="height: 100vh;" autoplay muted></video>
    </div>
    <script>
        const API_URL = "/api/verify_face"
        const video = document.getElementById('video')
        let isVerifying = false
        var staticUrl = "{% static 'assets' %}";
        Promise.all([
            faceapi.loadSsdMobilenetv1Model(staticUrl + "/models/"),
        ]).then(startVideo)

        function startVideo() {
            navigator.getUserMedia(
                { video: {} },
                stream => video.srcObject = stream,
                err => console.error(err)
            )
        }

        async function captureAndSendFrame() {
            const canvas = document.createElement("canvas");
            canvas.width = video.clientWidth;
            canvas.height = video.clientHeight;
            const ctx = canvas.getContext("2d");

            // Draw video frame to canvas
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            const blob = await new Promise(resolve => canvas.toBlob(resolve, "image/jpeg"));

            // Convert to Blob (JPEG)
            const formData = new FormData();
            formData.append("image", blob, "image.jpg");

            try {
                const response = await fetch(API_URL, {
                    method: "POST",
                    body: formData,
                    headers:{
                        "x-csrftoken": {{csrf_token}}
                    },
                    credentials: "include"
                });

                const result = await response.json();
                return result
            } catch (error) {
                console.error("Error sending frame:", error);
                return []
            }
        }

        video.addEventListener('play', () => {
            const displaySize = { width: video.clientWidth, height: video.clientHeight }
            const canvas = faceapi.createCanvasFromMedia(video)
            document.getElementById("container").append(canvas)
            faceapi.matchDimensions(canvas, displaySize)
            setInterval(async () => {
                const detections = await faceapi.detectAllFaces(video)
                if (!isVerifying && detections.length){
                    isVerifying = true
                    const results = await captureAndSendFrame()
                    if (results.length){
                        const boxesWithText = []    
                        results.forEach((result)=>{
                            const {x,y,width,height,name} = result
                            canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height)
                            boxesWithText.push(new faceapi.LabeledBox(new faceapi.Rect(x, y, width, height), name),)
                        })
                        faceapi.draw.drawDetections(canvas, boxesWithText)
                    }
                    isVerifying = false
                }
                else{
                    const resizedDetections = faceapi.resizeResults(detections, displaySize)
                    canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height)
                    faceapi.draw.drawDetections(canvas, resizedDetections)
                }
                
            }, 1000)
        })
    </script>

</body>
</html>
